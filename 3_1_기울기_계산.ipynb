{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMeQhk9mGbOLf+z56Ekubd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imhyunho99/2023-1--Deaplearning_Framework/blob/main/3_1_%EA%B8%B0%EC%9A%B8%EA%B8%B0_%EA%B3%84%EC%82%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 단순한 기울기 계산 \n",
        "\n",
        "- z = 2x^2+3"
      ],
      "metadata": {
        "id": "iweeKXjvepYE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "6hrw63KXeuTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x를 [2.0,3.0]의 값을 가진 텐서로 초기화 해주고 기울기 계산을 True로 켜 놓습니다. \n",
        "# z = 2x^2+3\n",
        "\n",
        "x = torch.tensor(data=[2.0,3.0],requires_grad=True)\n",
        "y = x**2\n",
        "z = 2*y +3"
      ],
      "metadata": {
        "id": "LXiMDA_zexPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://pytorch.org/docs/stable/autograd.html?highlight=backward#torch.autograd.backward\n",
        "\n",
        "# 목표값을 지정합니다. \n",
        "target = torch.tensor([3.0,4.0])\n",
        "\n",
        "# z와 목표값의 절대값 차이를 계산합니다. \n",
        "# backward는 스칼라 값에 대해서 동작하기 때문에 길이 2짜리 텐서인 loss를 torch.sum을 통해 하나의 숫자로 바꿔줍니다.\n",
        "loss = torch.sum(torch.abs(z-target))\n",
        "\n",
        "# 그리고 스칼라 값이 된 loss에 대해 backward를 적용합니다.\n",
        "loss.backward()\n",
        "\n",
        "# 여기서 y와 z는 기울기가 None으로 나오는데 이는 x,y,z중에 x만이 leaf node이기 때문입니다.\n",
        "print(x.grad, y.grad, z.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qp2J8mM4ez-z",
        "outputId": "dd6446fd-f38f-4820-e7c2-02e8d6c3b9ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 8., 12.]) None None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-7b4d3095ec11>:14: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:480.)\n",
            "  print(x.grad, y.grad, z.grad)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "plzEJNpQe01W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}