{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imhyunho99/2023-1--Deaplearning_Framework/blob/main/5_7_3_ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "uYEoda25h6UK"
      },
      "source": [
        "# Residual Networks\n",
        "\n",
        "- 앞선 네트워크에서 설명한 부분은 생략했습니다.\n",
        "- 2015 ILSVRC 1st place\n",
        "- ResNet-50\n",
        "\n",
        "![alt text](https://www.codeproject.com/KB/AI/1248963/resnet.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZHiDXM0iOPa",
        "outputId": "dd412080-7b9a-4a84-876f-31c1712095bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 975
        }
      },
      "source": [
        "# 런타임 유형 GPU 모드로 변경\n",
        "!pip install torch torchvision\n",
        "\n",
        "!pip install pillow==4.1.1\n",
        "%reload_ext autoreload\n",
        "%autoreload"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (2.0.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (0.15.1+cu118)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch) (3.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (16.0.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.22.4)\n",
            "Collecting pillow!=8.3.*,>=5.3.0\n",
            "  Downloading Pillow-9.5.0-cp39-cp39-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: pillow\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 4.1.1\n",
            "    Uninstalling Pillow-4.1.1:\n",
            "      Successfully uninstalled Pillow-4.1.1\n",
            "Successfully installed pillow-9.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pillow==4.1.1\n",
            "  Using cached Pillow-4.1.1-cp39-cp39-linux_x86_64.whl\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.9/dist-packages (from pillow==4.1.1) (0.46)\n",
            "Installing collected packages: pillow\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 9.5.0\n",
            "    Uninstalling Pillow-9.5.0:\n",
            "      Successfully uninstalled Pillow-9.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.15.1+cu118 requires pillow!=8.3.*,>=5.3.0, but you have pillow 4.1.1 which is incompatible.\n",
            "scikit-image 0.19.3 requires pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0, but you have pillow 4.1.1 which is incompatible.\n",
            "matplotlib 3.7.1 requires pillow>=6.2.0, but you have pillow 4.1.1 which is incompatible.\n",
            "imageio 2.25.1 requires pillow>=8.3.2, but you have pillow 4.1.1 which is incompatible.\n",
            "fastai 2.7.12 requires pillow>6.0.0, but you have pillow 4.1.1 which is incompatible.\n",
            "dopamine-rl 4.0.6 requires Pillow>=7.0.0, but you have pillow 4.1.1 which is incompatible.\n",
            "bokeh 2.4.3 requires pillow>=7.1.0, but you have pillow 4.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pillow-4.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKtJXZk5iRvT",
        "outputId": "cb1fcfae-defe-49ff-ecb4-dabf11ac3fec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!rm -r images\n",
        "import os \n",
        "\n",
        "try:\n",
        "  os.mkdir(\"images\")\n",
        "  os.mkdir(\"images/dogs\")\n",
        "  os.mkdir(\"images/cats\")\n",
        "except:\n",
        "  pass\n",
        "\n",
        "!wget https://i.kinja-img.com/gawker-media/image/upload/s--WFkXeene--/c_scale,f_auto,fl_progressive,q_80,w_800/ol9ceoqxidudap8owlwn.jpg -P images/dogs\n",
        "!wget https://www.rspcansw.org.au/wp-content/uploads/2017/08/50_a-feature_dogs-and-puppies_mobile.jpg -P images/dogs\n",
        "  \n",
        "!wget https://www.catster.com/wp-content/uploads/2018/05/A-gray-cat-crying-looking-upset.jpg -P images/cats\n",
        "!wget https://www.scarymommy.com/wp-content/uploads/2018/01/c1.jpg?w=700 -P images/cats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-19 04:37:14--  https://i.kinja-img.com/gawker-media/image/upload/s--WFkXeene--/c_scale,f_auto,fl_progressive,q_80,w_800/ol9ceoqxidudap8owlwn.jpg\n",
            "Resolving i.kinja-img.com (i.kinja-img.com)... 151.101.2.166, 151.101.194.166, 151.101.66.166, ...\n",
            "Connecting to i.kinja-img.com (i.kinja-img.com)|151.101.2.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 36509 (36K) [image/jpeg]\n",
            "Saving to: ‘images/dogs/ol9ceoqxidudap8owlwn.jpg’\n",
            "\n",
            "\rol9ceoqxidudap8owlw   0%[                    ]       0  --.-KB/s               \rol9ceoqxidudap8owlw 100%[===================>]  35.65K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-04-19 04:37:15 (80.9 MB/s) - ‘images/dogs/ol9ceoqxidudap8owlwn.jpg’ saved [36509/36509]\n",
            "\n",
            "--2023-04-19 04:37:15--  https://www.rspcansw.org.au/wp-content/uploads/2017/08/50_a-feature_dogs-and-puppies_mobile.jpg\n",
            "Resolving www.rspcansw.org.au (www.rspcansw.org.au)... 101.0.86.38\n",
            "Connecting to www.rspcansw.org.au (www.rspcansw.org.au)|101.0.86.38|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 130940 (128K) [image/jpeg]\n",
            "Saving to: ‘images/dogs/50_a-feature_dogs-and-puppies_mobile.jpg’\n",
            "\n",
            "50_a-feature_dogs-a 100%[===================>] 127.87K   458KB/s    in 0.3s    \n",
            "\n",
            "2023-04-19 04:37:15 (458 KB/s) - ‘images/dogs/50_a-feature_dogs-and-puppies_mobile.jpg’ saved [130940/130940]\n",
            "\n",
            "--2023-04-19 04:37:16--  https://www.catster.com/wp-content/uploads/2018/05/A-gray-cat-crying-looking-upset.jpg\n",
            "Resolving www.catster.com (www.catster.com)... 54.192.150.30, 54.192.150.77, 54.192.150.6, ...\n",
            "Connecting to www.catster.com (www.catster.com)|54.192.150.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 165145 (161K) [image/jpeg]\n",
            "Saving to: ‘images/cats/A-gray-cat-crying-looking-upset.jpg’\n",
            "\n",
            "A-gray-cat-crying-l 100%[===================>] 161.27K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2023-04-19 04:37:16 (37.7 MB/s) - ‘images/cats/A-gray-cat-crying-looking-upset.jpg’ saved [165145/165145]\n",
            "\n",
            "--2023-04-19 04:37:16--  https://www.scarymommy.com/wp-content/uploads/2018/01/c1.jpg?w=700\n",
            "Resolving www.scarymommy.com (www.scarymommy.com)... 54.192.150.55, 54.192.150.30, 54.192.150.60, ...\n",
            "Connecting to www.scarymommy.com (www.scarymommy.com)|54.192.150.55|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2023-04-19 04:37:16 ERROR 404: Not Found.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "RgQsBb2Ah6UL"
      },
      "source": [
        "## 1. Settings\n",
        "### 1) Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2Zl8jNzh6UM"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import torch.utils.data as data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rMvBvxNh6UP"
      },
      "source": [
        "### 2) Hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgRtVCskh6UQ"
      },
      "source": [
        "batch_size= 1\n",
        "learning_rate = 0.0002\n",
        "num_epoch = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ih_uqbrNh6US"
      },
      "source": [
        "## 2. Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyLiekSlh6UT"
      },
      "source": [
        "img_dir = \"./images\"\n",
        "img_data = dset.ImageFolder(img_dir, transforms.Compose([\n",
        "                                      transforms.Resize(256),                   \n",
        "                                      transforms.RandomResizedCrop(224),        \n",
        "                                      transforms.RandomHorizontalFlip(),        \n",
        "                                      transforms.ToTensor(),                    \n",
        "            ]))\n",
        "\n",
        "train_loader = data.DataLoader(img_data, batch_size=batch_size,\n",
        "                            shuffle=True, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DArnCQsh6UV"
      },
      "source": [
        "## 3. Model \n",
        "### 1) Basic Block\n",
        "\n",
        "- 컨볼루션 연산과 활성화함수는 항상 붙어 있기 때문에 이를 함수로 만들었습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGD1pVFbh6UV"
      },
      "source": [
        "def conv_block_1(in_dim,out_dim,act_fn,stride=1):\n",
        "    model = nn.Sequential(\n",
        "        nn.Conv2d(in_dim,out_dim, kernel_size=1, stride=stride),\n",
        "        act_fn,\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "def conv_block_3(in_dim,out_dim,act_fn):\n",
        "    model = nn.Sequential(\n",
        "        nn.Conv2d(in_dim,out_dim, kernel_size=3, stride=1, padding=1),\n",
        "        act_fn,\n",
        "    )\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBVXy532h6UX"
      },
      "source": [
        "### 2) Bottle Neck Module\n",
        "- Bottle Neck 모듈은 [1x1 컨볼루션 -> 3x3 컨볼루션 -> 1x1 컨볼루션]으로 이루어집니다.\n",
        "- 맨 위에 네트워크 구조에서도 볼 수 있듯이 실선은 크기가 변하지 않는 경우, 점선은 크기가 줄어드는 경우입니다. \n",
        "- 이를 한번에 구현하기 위해 down이라는 변수로 크기 감소 여부를 표시하고 조건문으로 경우의 수를 나눠 구현했습니다.\n",
        "- 또한 ResNet의 Skip-connection은 단순 더하기로 정의되어 있기 때문에 특성지도의 크기를 일치시켜야 합니다. \n",
        "- 이를 위해 차원을 맞춰주는 역할로 dim_equalizer라는 것을 정의했습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGmxNdtwh6UY"
      },
      "source": [
        "class BottleNeck(nn.Module):\n",
        "    def __init__(self,in_dim,mid_dim,out_dim,act_fn,down=False):\n",
        "        super(BottleNeck,self).__init__()\n",
        "        self.down=down\n",
        "        \n",
        "        # 특성지도의 크기가 감소하는 경우\n",
        "        if self.down:\n",
        "            self.layer = nn.Sequential(\n",
        "              conv_block_1(in_dim,mid_dim,act_fn,2),\n",
        "              conv_block_3(mid_dim,mid_dim,act_fn),\n",
        "              conv_block_1(mid_dim,out_dim,act_fn),\n",
        "            )\n",
        "            self.downsample = nn.Conv2d(in_dim,out_dim,1,2)\n",
        "            \n",
        "        # 특성지도의 크기가 그대로인 경우\n",
        "        else:\n",
        "            self.layer = nn.Sequential(\n",
        "                conv_block_1(in_dim,mid_dim,act_fn),\n",
        "                conv_block_3(mid_dim,mid_dim,act_fn),\n",
        "                conv_block_1(mid_dim,out_dim,act_fn),\n",
        "            )\n",
        "            \n",
        "        # 더하기를 위해 차원을 맞춰주는 부분\n",
        "        self.dim_equalizer = nn.Conv2d(in_dim,out_dim,kernel_size=1)\n",
        "                  \n",
        "    def forward(self,x):\n",
        "        if self.down:\n",
        "            downsample = self.downsample(x)\n",
        "            out = self.layer(x)\n",
        "            out = out + downsample\n",
        "        else:\n",
        "            out = self.layer(x)\n",
        "            if x.size() is not out.size():\n",
        "                x = self.dim_equalizer(x)\n",
        "            out = out + x\n",
        "        return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQz7fV7sh6UZ"
      },
      "source": [
        "### 2) ResNet Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "raEFPjZ9h6Ua"
      },
      "source": [
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, base_dim, num_classes=2):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.act_fn = nn.ReLU()\n",
        "        self.layer_1 = nn.Sequential(\n",
        "            nn.Conv2d(3,base_dim,7,2,3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(3,2,1),\n",
        "        )\n",
        "        self.layer_2 = nn.Sequential(\n",
        "            BottleNeck(base_dim,base_dim,base_dim*4,self.act_fn),\n",
        "            BottleNeck(base_dim*4,base_dim,base_dim*4,self.act_fn),\n",
        "            BottleNeck(base_dim*4,base_dim,base_dim*4,self.act_fn,down=True),\n",
        "        )   \n",
        "        self.layer_3 = nn.Sequential(\n",
        "            BottleNeck(base_dim*4,base_dim*2,base_dim*8,self.act_fn),\n",
        "            BottleNeck(base_dim*8,base_dim*2,base_dim*8,self.act_fn),\n",
        "            BottleNeck(base_dim*8,base_dim*2,base_dim*8,self.act_fn),\n",
        "            BottleNeck(base_dim*8,base_dim*2,base_dim*8,self.act_fn,down=True),\n",
        "        )\n",
        "        self.layer_4 = nn.Sequential(\n",
        "            BottleNeck(base_dim*8,base_dim*4,base_dim*16,self.act_fn),\n",
        "            BottleNeck(base_dim*16,base_dim*4,base_dim*16,self.act_fn),\n",
        "            BottleNeck(base_dim*16,base_dim*4,base_dim*16,self.act_fn),            \n",
        "            BottleNeck(base_dim*16,base_dim*4,base_dim*16,self.act_fn),\n",
        "            BottleNeck(base_dim*16,base_dim*4,base_dim*16,self.act_fn),\n",
        "            BottleNeck(base_dim*16,base_dim*4,base_dim*16,self.act_fn,down=True),\n",
        "        )\n",
        "        self.layer_5 = nn.Sequential(\n",
        "            BottleNeck(base_dim*16,base_dim*8,base_dim*32,self.act_fn),\n",
        "            BottleNeck(base_dim*32,base_dim*8,base_dim*32,self.act_fn),\n",
        "            BottleNeck(base_dim*32,base_dim*8,base_dim*32,self.act_fn),\n",
        "        )\n",
        "        self.avgpool = nn.AvgPool2d(7,1) \n",
        "        self.fc_layer = nn.Linear(base_dim*32,num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer_1(x)\n",
        "        out = self.layer_2(out)\n",
        "        out = self.layer_3(out)\n",
        "        out = self.layer_4(out)\n",
        "        out = self.layer_5(out)\n",
        "        out = self.avgpool(out)\n",
        "        out = out.view(batch_size,-1)\n",
        "        out = self.fc_layer(out)\n",
        "        \n",
        "        return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-QPov_mh6Ue"
      },
      "source": [
        "## 4. Optimizer & Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBLw0OSth6Uf",
        "outputId": "211babf7-2212-4252-8b25-b4f780a8dba6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "    \n",
        "model = ResNet(base_dim=64).to(device)\n",
        "\n",
        "'''\n",
        "for i in model.children():\n",
        "    print(i)\n",
        "'''\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(),lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZHDWV01h6Ui"
      },
      "source": [
        "## 5. Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QTWZkyLh6Ui",
        "outputId": "30df0dd7-c1ba-4d4f-ac01-46a817c0e8f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for i in range(num_epoch):\n",
        "    for j,[image,label] in enumerate(train_loader):\n",
        "        x = image.to(device)\n",
        "        y_= label.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        output = model.forward(x)\n",
        "        loss = loss_func(output,y_)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if i % 10 ==0:\n",
        "        print(loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.0453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4862, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4116, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.1140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.0607, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.0777, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4338, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4077, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p33BQK1niuun"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}