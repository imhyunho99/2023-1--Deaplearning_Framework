{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imhyunho99/2023-1--Deaplearning_Framework/blob/main/(PR)1_Char_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShSWYFSlENxq"
      },
      "source": [
        "# Simple Character LSTM\n",
        "# Char RNN에서 설명한 부분은 생략했습니다.\n",
        "\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPTxJL3qENxu",
        "outputId": "e65606e4-487b-42cc-c712-0ccdc036ef48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Preprocessing string data\n",
        "# alphabet(0-25), space(26),..., start, end \n",
        "\n",
        "string = \"hello pytorch. how long can a rnn cell remember? show me your limit! limit limit limit\"\n",
        "chars = \"abcdefghijklmnopqrstuvwxyz ?!.,:;01\"\n",
        "char_list = [i for i in chars]\n",
        "char_len = len(char_list)\n",
        "\n",
        "char_len"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-xqHFGdENx0"
      },
      "source": [
        "# String to onehot vector\n",
        "# [0 0 0 ... 1 0] -> Start\n",
        "# [1 0 0 ... 0 0] -> a \n",
        "# [0 1 0 ... 0 0] -> b\n",
        "# [0 0 1 ... 0 0] -> c\n",
        "# [0 0 0 ... 0 1] -> end\n",
        "\n",
        "def string_to_onehot(string):\n",
        "    start = np.zeros(shape=char_len ,dtype=int)\n",
        "    end = np.zeros(shape=char_len ,dtype=int)\n",
        "    start[-2] = 1\n",
        "    end[-1] = 1\n",
        "    for i in string:\n",
        "        idx = char_list.index(i)\n",
        "        zero = np.zeros(shape=char_len ,dtype=int)\n",
        "        zero[idx]=1\n",
        "        start = np.vstack([start,zero])\n",
        "    output = np.vstack([start,end])\n",
        "    return output"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_gqctcyENx3"
      },
      "source": [
        "# Onehot vector to word\n",
        "\n",
        "\n",
        "def onehot_to_word(onehot_1):\n",
        "    onehot = torch.Tensor.numpy(onehot_1)\n",
        "    return char_list[onehot.argmax()]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjb-I6DlENx6",
        "outputId": "3293b781-24d8-4f20-8051-8cab277c86d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 하이퍼파라미터 설정\n",
        "# 문자열을 단어 하나씩 잘러서 사용하는걸로 구현해서 batch_size 1로 고정입니다.\n",
        "# batch_size가 1보다 큰 경우는 다음 실습코드에 있습니다.\n",
        "batch_size = 1\n",
        "\n",
        "# seq_len는 바꿔도 학습은 되지만 테스트시 편의성을 위해 1로 설정했습니다.\n",
        "seq_len = 1\n",
        "\n",
        "# num_layers는 입력 형식에만 맞게 형태를 바꿔주면 됩니다.\n",
        "num_layers = 3\n",
        "input_size = char_len#35\n",
        "hidden_size = 35 \n",
        "lr = 0.01\n",
        "num_epochs = 1000\n",
        "\n",
        "one_hot = torch.from_numpy(string_to_onehot(string)).type_as(torch.FloatTensor())\n",
        "\n",
        "print(one_hot.size())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([88, 35])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGTtv6T5ENx9"
      },
      "source": [
        "# RNN with 1 hidden layer\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size,num_layers):\n",
        "        super(RNN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size,hidden_size,num_layers)\n",
        "        \n",
        "    def forward(self,input_,hidden,cell):\n",
        "        output,(hidden,cell) = self.lstm(input_,(hidden,cell))#tuple(hidden,cell)\n",
        "        return output,hidden,cell\n",
        "    \n",
        "    def init_hidden_cell(self):\n",
        "        hidden = torch.zeros(num_layers,batch_size,hidden_size)\n",
        "        cell = torch.zeros(num_layers,batch_size,hidden_size)\n",
        "        return hidden,cell\n",
        "    \n",
        "rnn = RNN(input_size,hidden_size, num_layers)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Gt2qWjRENyA"
      },
      "source": [
        "# Loss function & Optimizer\n",
        "\n",
        "loss_func = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(rnn.parameters(), lr=lr)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0xJsfTQENyD",
        "outputId": "4be97fb8-2773-48e6-fcdb-1509f7660406",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "j=0\n",
        "input_data = one_hot[j:j+seq_len].view(seq_len, batch_size, input_size)\n",
        "print(input_data.size())\n",
        "\n",
        "hidden,cell = rnn.init_hidden_cell()\n",
        "print(hidden.size(),cell.size())\n",
        "\n",
        "output, hidden,cell = rnn(input_data,hidden,cell)\n",
        "print(output.size(),hidden.size(),cell.size())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 35])\n",
            "torch.Size([3, 1, 35]) torch.Size([3, 1, 35])\n",
            "torch.Size([1, 1, 35]) torch.Size([3, 1, 35]) torch.Size([3, 1, 35])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdMuzai1_abV",
        "outputId": "16555a04-6934-47cc-8a76-27b989b75345"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92Vh1bteEXKu",
        "outputId": "9074454c-2907-423b-c35e-270d3905c020",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "unroll_len = one_hot.size()[0]//seq_len -1\n",
        "for i in range(num_epochs):\n",
        "    hidden,cell = rnn.init_hidden_cell()\n",
        "    \n",
        "    loss = 0\n",
        "    for j in range(unroll_len):\n",
        "        input_data = one_hot[j:j+seq_len].view(seq_len,batch_size,input_size) \n",
        "        label = one_hot[j+1:j+seq_len+1].view(seq_len,batch_size,input_size)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output, hidden, cell = rnn(input_data,hidden,cell)\n",
        "        loss += loss_func(output.view(1,-1),label.view(1,-1))\n",
        "        \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i%10 ==0:\n",
        "        print(loss)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.8502, grad_fn=<AddBackward0>)\n",
            "tensor(2.2782, grad_fn=<AddBackward0>)\n",
            "tensor(2.1866, grad_fn=<AddBackward0>)\n",
            "tensor(2.0682, grad_fn=<AddBackward0>)\n",
            "tensor(1.7588, grad_fn=<AddBackward0>)\n",
            "tensor(1.3466, grad_fn=<AddBackward0>)\n",
            "tensor(0.8482, grad_fn=<AddBackward0>)\n",
            "tensor(0.4885, grad_fn=<AddBackward0>)\n",
            "tensor(0.2602, grad_fn=<AddBackward0>)\n",
            "tensor(0.1482, grad_fn=<AddBackward0>)\n",
            "tensor(0.0827, grad_fn=<AddBackward0>)\n",
            "tensor(0.0504, grad_fn=<AddBackward0>)\n",
            "tensor(0.0363, grad_fn=<AddBackward0>)\n",
            "tensor(0.0280, grad_fn=<AddBackward0>)\n",
            "tensor(0.0224, grad_fn=<AddBackward0>)\n",
            "tensor(0.0189, grad_fn=<AddBackward0>)\n",
            "tensor(0.0164, grad_fn=<AddBackward0>)\n",
            "tensor(0.0155, grad_fn=<AddBackward0>)\n",
            "tensor(0.0134, grad_fn=<AddBackward0>)\n",
            "tensor(0.0119, grad_fn=<AddBackward0>)\n",
            "tensor(0.0103, grad_fn=<AddBackward0>)\n",
            "tensor(0.0096, grad_fn=<AddBackward0>)\n",
            "tensor(0.0085, grad_fn=<AddBackward0>)\n",
            "tensor(0.0078, grad_fn=<AddBackward0>)\n",
            "tensor(0.0073, grad_fn=<AddBackward0>)\n",
            "tensor(0.0069, grad_fn=<AddBackward0>)\n",
            "tensor(0.0066, grad_fn=<AddBackward0>)\n",
            "tensor(0.0064, grad_fn=<AddBackward0>)\n",
            "tensor(0.0062, grad_fn=<AddBackward0>)\n",
            "tensor(0.0060, grad_fn=<AddBackward0>)\n",
            "tensor(0.0058, grad_fn=<AddBackward0>)\n",
            "tensor(0.0059, grad_fn=<AddBackward0>)\n",
            "tensor(0.0052, grad_fn=<AddBackward0>)\n",
            "tensor(0.0047, grad_fn=<AddBackward0>)\n",
            "tensor(0.0041, grad_fn=<AddBackward0>)\n",
            "tensor(0.0039, grad_fn=<AddBackward0>)\n",
            "tensor(0.0038, grad_fn=<AddBackward0>)\n",
            "tensor(0.0037, grad_fn=<AddBackward0>)\n",
            "tensor(0.0037, grad_fn=<AddBackward0>)\n",
            "tensor(0.0035, grad_fn=<AddBackward0>)\n",
            "tensor(0.0035, grad_fn=<AddBackward0>)\n",
            "tensor(0.0034, grad_fn=<AddBackward0>)\n",
            "tensor(0.0033, grad_fn=<AddBackward0>)\n",
            "tensor(0.0032, grad_fn=<AddBackward0>)\n",
            "tensor(0.0032, grad_fn=<AddBackward0>)\n",
            "tensor(0.0031, grad_fn=<AddBackward0>)\n",
            "tensor(0.0043, grad_fn=<AddBackward0>)\n",
            "tensor(0.0031, grad_fn=<AddBackward0>)\n",
            "tensor(0.0030, grad_fn=<AddBackward0>)\n",
            "tensor(0.0029, grad_fn=<AddBackward0>)\n",
            "tensor(0.0028, grad_fn=<AddBackward0>)\n",
            "tensor(0.0027, grad_fn=<AddBackward0>)\n",
            "tensor(0.0027, grad_fn=<AddBackward0>)\n",
            "tensor(0.0027, grad_fn=<AddBackward0>)\n",
            "tensor(0.0028, grad_fn=<AddBackward0>)\n",
            "tensor(0.0026, grad_fn=<AddBackward0>)\n",
            "tensor(0.0026, grad_fn=<AddBackward0>)\n",
            "tensor(0.0025, grad_fn=<AddBackward0>)\n",
            "tensor(0.0025, grad_fn=<AddBackward0>)\n",
            "tensor(0.0025, grad_fn=<AddBackward0>)\n",
            "tensor(0.0025, grad_fn=<AddBackward0>)\n",
            "tensor(0.0024, grad_fn=<AddBackward0>)\n",
            "tensor(0.0025, grad_fn=<AddBackward0>)\n",
            "tensor(0.0025, grad_fn=<AddBackward0>)\n",
            "tensor(0.0024, grad_fn=<AddBackward0>)\n",
            "tensor(0.0024, grad_fn=<AddBackward0>)\n",
            "tensor(0.0023, grad_fn=<AddBackward0>)\n",
            "tensor(0.0023, grad_fn=<AddBackward0>)\n",
            "tensor(0.0023, grad_fn=<AddBackward0>)\n",
            "tensor(0.0023, grad_fn=<AddBackward0>)\n",
            "tensor(0.0023, grad_fn=<AddBackward0>)\n",
            "tensor(0.0023, grad_fn=<AddBackward0>)\n",
            "tensor(0.0023, grad_fn=<AddBackward0>)\n",
            "tensor(0.0023, grad_fn=<AddBackward0>)\n",
            "tensor(0.0022, grad_fn=<AddBackward0>)\n",
            "tensor(0.0022, grad_fn=<AddBackward0>)\n",
            "tensor(0.0022, grad_fn=<AddBackward0>)\n",
            "tensor(0.0022, grad_fn=<AddBackward0>)\n",
            "tensor(0.0023, grad_fn=<AddBackward0>)\n",
            "tensor(0.0022, grad_fn=<AddBackward0>)\n",
            "tensor(0.0022, grad_fn=<AddBackward0>)\n",
            "tensor(0.0022, grad_fn=<AddBackward0>)\n",
            "tensor(0.0022, grad_fn=<AddBackward0>)\n",
            "tensor(0.0022, grad_fn=<AddBackward0>)\n",
            "tensor(0.0021, grad_fn=<AddBackward0>)\n",
            "tensor(0.0021, grad_fn=<AddBackward0>)\n",
            "tensor(0.0021, grad_fn=<AddBackward0>)\n",
            "tensor(0.0022, grad_fn=<AddBackward0>)\n",
            "tensor(0.0024, grad_fn=<AddBackward0>)\n",
            "tensor(0.0022, grad_fn=<AddBackward0>)\n",
            "tensor(0.0021, grad_fn=<AddBackward0>)\n",
            "tensor(0.0021, grad_fn=<AddBackward0>)\n",
            "tensor(0.0021, grad_fn=<AddBackward0>)\n",
            "tensor(0.0021, grad_fn=<AddBackward0>)\n",
            "tensor(0.0021, grad_fn=<AddBackward0>)\n",
            "tensor(0.0021, grad_fn=<AddBackward0>)\n",
            "tensor(0.0020, grad_fn=<AddBackward0>)\n",
            "tensor(0.0020, grad_fn=<AddBackward0>)\n",
            "tensor(0.0020, grad_fn=<AddBackward0>)\n",
            "tensor(0.0020, grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VJSE-SlENyH",
        "outputId": "3616c62b-fd9f-4a88-c543-b533cb878e82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "hidden,cell = rnn.init_hidden_cell()\n",
        "\n",
        "for j in range(unroll_len-1):\n",
        "    input_data = one_hot[j:j+1].view(1,batch_size,hidden_size) \n",
        "    label = one_hot[j+1:j+1+1].view(1,batch_size,hidden_size) \n",
        "    \n",
        "    output, hidden, cell = rnn(input_data,hidden,cell)\n",
        "    print(onehot_to_word(output.data),end=\"\") "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello pytorch. how long can a rnn cell remember? show me your limit! limit limit limit"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwG1rY0OTZqn"
      },
      "source": [],
      "execution_count": 21,
      "outputs": []
    }
  ]
}