{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imhyunho99/2023-1--Deaplearning_Framework/blob/main/7_3_%EB%93%9C%EB%A1%AD%EC%95%84%EC%9B%83(Dropout).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTpEe75iMeU1"
      },
      "source": [
        "# 드롭아웃 Dropout\n",
        "\n",
        "- nn.Dropout(p=0.5, inplace=False)\n",
        "- Dropout으로 중요한 노드가 꺼진다 해도 오히려 좋을 수 있다. 왜냐하면 그만큼 주변 다른 노드들에 중요도가 분산되므로 프로그램이 좋은 방향으로 발전 할 수 있다.\n",
        "\n",
        "![대체 텍스트](https://cdn-images-1.medium.com/max/2400/1*iWQzxhVlvadk6VAJjsgXgg.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DSxn-sXOblF",
        "outputId": "7af5393b-b9ad-4be5-bdf2-bee1c9ff6972",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 런타임 유형을 GPU로 바꾸시길 추천드립니다.\n",
        "!pip install torch torchvision"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or3S0EydMeU3"
      },
      "source": [
        "## 1. Settings\n",
        "### 1) Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziYyF1xXMeU5"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCCW6Q4NMeU9"
      },
      "source": [
        "### 2) Set hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpaWtPPnMeU-"
      },
      "source": [
        "batch_size = 256\n",
        "learning_rate = 0.0002\n",
        "num_epoch = 10"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OK1ZfhAmMeVB"
      },
      "source": [
        "## 2. Data\n",
        "\n",
        "### 1) Download Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAo-JKp6MeVB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "435ea53f-7db0-4081-b66a-5a5e1654af9f"
      },
      "source": [
        "mnist_train = dset.MNIST(\"./\", train=True, transform=transforms.ToTensor(), target_transform=None, download=True)\n",
        "mnist_test = dset.MNIST(\"./\", train=False, transform=transforms.ToTensor(), target_transform=None, download=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 323823594.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 24407756.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 188649519.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 6510775.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0K3-l6uMeVF"
      },
      "source": [
        "### 2) Check Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqVubcD7MeVG",
        "outputId": "8a48091d-df2a-4419-b30b-e63731e77c45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(mnist_train.__getitem__(0)[0].size(), mnist_train.__len__())\n",
        "mnist_test.__getitem__(0)[0].size(), mnist_test.__len__()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28]) 60000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 28, 28]), 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdmGkVE2MeVK"
      },
      "source": [
        "### 3) Set DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlqNtk_cMeVL"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(mnist_train,batch_size=batch_size, shuffle=True,num_workers=2,drop_last=True)\n",
        "test_loader = torch.utils.data.DataLoader(mnist_test,batch_size=batch_size, shuffle=False,num_workers=2,drop_last=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DpOHGAaMeVN"
      },
      "source": [
        "## 3. Model & Optimizer\n",
        "\n",
        "### 1) CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FljLkVynMeVO"
      },
      "source": [
        "# 드롭아웃을 중간중간에 넣어줌으로써 모델이 오버피팅하는 경우 이를 어느정도 극복할 수 있습니다.\n",
        "# 정형화에서 눈치채신분도 계시겠지만 오버피팅하지 않는 상태에서 정형화나 드롭아웃을 넣으면 오히려 학습이 잘 안됩니다.\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN,self).__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Conv2d(1,16,3,padding=1),  # 28\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(0.2),\n",
        "            nn.Conv2d(16,32,3,padding=1), # 28\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(0.2),\n",
        "            nn.MaxPool2d(2,2),            # 14\n",
        "            nn.Conv2d(32,64,3,padding=1), # 14\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(0.2), #==> 요 코드=dropout\n",
        "            nn.MaxPool2d(2,2)             # 7\n",
        "        )\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Linear(64*7*7,100),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(100,10)\n",
        "        )       \n",
        "        \n",
        "    def forward(self,x):\n",
        "        out = self.layer(x)\n",
        "        out = out.view(batch_size,-1)\n",
        "        out = self.fc_layer(out)\n",
        "        return out"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVJSa-TvMeVQ"
      },
      "source": [
        "### 2) Loss func & Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBFlgVG8MeVR",
        "outputId": "b23f0c05-b5ba-4f26-9154-45e6457a7891",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "model = CNN().to(device)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71h4bU-TMeVU"
      },
      "source": [
        "## 4. Train "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNR52PKcMeVV",
        "outputId": "4056eadc-0248-4635-d464-ec6133e89a81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for i in range(num_epoch):\n",
        "    for j,[image,label] in enumerate(train_loader):\n",
        "        x = image.to(device)\n",
        "        y_= label.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        output = model.forward(x)\n",
        "        loss = loss_func(output,y_)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "    if i % 10 == 0: #이렇게 10번 돌리면 그냥 처음에만 나오고 쓸모없는게 됨ㅋ\n",
        "        print(loss)         "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.2999, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIigCuMgMeVY"
      },
      "source": [
        "#param_list = list(model.parameters())\n",
        "#print(param_list)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N08pbNC9MeVZ"
      },
      "source": [
        "## 5. Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTq1WKA0MeVa",
        "outputId": "ddd1e2ae-6c88-4af5-8cdd-9d1e0bd5e011",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# 배치정규화나 드롭아웃은 학습할때와 테스트 할때 다르게 동작하기 때문에 모델을 evaluation 모드로 바꿔서 테스트해야합니다.\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  for image,label in test_loader:\n",
        "      x = image.to(device)\n",
        "      y_= label.to(device)\n",
        "\n",
        "      output = model.forward(x)\n",
        "      _,output_index = torch.max(output,1)\n",
        "\n",
        "      total += label.size(0)\n",
        "      correct += (output_index == y_).sum().float()\n",
        "\n",
        "  print(\"Accuracy of Test Data: {}\".format(100*correct/total))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Test Data: 10.897436141967773\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_epoch):\n",
        "    for j,[image,label] in enumerate(train_loader):\n",
        "        x = image.to(device)\n",
        "        y_= label.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        output = model.forward(x)\n",
        "        loss = loss_func(output,y_)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(loss)         "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nq0CHwSzKIwv",
        "outputId": "92125b59-211c-4204-99ce-7f10f5eb852e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.2953, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.2968, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.2971, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.2954, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.2917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.2926, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.2902, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.2883, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.2922, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.2850, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# 배치정규화나 드롭아웃은 학습할때와 테스트 할때 다르게 동작하기 때문에 모델을 evaluation 모드로 바꿔서 테스트해야합니다. test할때는 drpoout, regular을 모두 사용해야 하기 떄문에 평가모드 사용\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  for image,label in test_loader:\n",
        "      x = image.to(device)\n",
        "      y_= label.to(device)\n",
        "\n",
        "      output = model.forward(x)\n",
        "      _,output_index = torch.max(output,1)\n",
        "\n",
        "      total += label.size(0)\n",
        "      correct += (output_index == y_).sum().float()\n",
        "\n",
        "  print(\"Accuracy of Test Data: {}\".format(100*correct/total))\n",
        "  #Dropout 넣으니까 5% 오르긴 하는데..."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0WConNoKLVh",
        "outputId": "0deea7ec-f5b1-4ebc-b90e-3c7ccfaceb55"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Test Data: 15.154247283935547\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**정규화와 드롭아웃의 장점**\n",
        "\n",
        "모델에는 변화를 주지 않으면서 결과를 더 좋게 만들 수 있다."
      ],
      "metadata": {
        "id": "yJsHMYuIIb8e"
      }
    }
  ]
}