{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imhyunho99/2023-1--Deaplearning_Framework/blob/main/7_2_%EC%A0%95%ED%98%95%ED%99%94(Weight_Regularization).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 오버피팅과 언더피팅\n",
        "\n",
        "\n",
        "- 수용력과 오차 그래프\n",
        "- 일반화 : 학습 오차와 테스트 오차의 차이\n",
        "\n"
      ],
      "metadata": {
        "id": "Vep6gCEh756J"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7um1PN1E40L"
      },
      "source": [
        "# 정형화 Weight Regularization \n",
        "\n",
        "- 최적화 함수의 weight_decay 로 강도를 조절할 수 있습니다.\n",
        "- ex) torch.optim.SGD(params, lr=1, momentum=0, dampening=0, weight_decay=0, nesterov=False)\n",
        "- 모델이 오버피팅할 경우, 적절한 강도로 정형화를 걸어주면 이를 어느정도 극복할 수 있습니다.\n",
        "- 정형화 부분 빼고는 컨볼루션 인공신경망 코드와 동일합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNDOrPaMFG1d",
        "outputId": "97e21342-04bc-48e9-ccdf-16f122ac03df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 런타임 유형을 GPU로 바꾸시길 추천드립니다.\n",
        "!pip install torch torchvision"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfWidCHbE40M"
      },
      "source": [
        "## 1. Settings\n",
        "### 1) Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0O_DUBzxE405"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCLu6xWaE40-"
      },
      "source": [
        "### 2) Set hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwkvjrAcE41A"
      },
      "source": [
        "batch_size = 256\n",
        "learning_rate = 0.0002\n",
        "num_epoch = 10"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObM5RlttE41E"
      },
      "source": [
        "## 2. Data\n",
        "\n",
        "### 1) Download Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsdXyu5UE41F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8af3b3b-5e48-4bfa-a317-b895eb2ad5ff"
      },
      "source": [
        "mnist_train = dset.MNIST(\"./\", train=True, transform=transforms.ToTensor(), target_transform=None, download=True)\n",
        "mnist_test = dset.MNIST(\"./\", train=False, transform=transforms.ToTensor(), target_transform=None, download=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 457227661.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 94342440.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 84241514.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 17224709.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0rdRoNDE41J"
      },
      "source": [
        "### 2) Check Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tu5PcIMcE41K",
        "outputId": "f76ce073-3393-4238-c92b-6ddf5a57c630",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(mnist_train.__getitem__(0)[0].size(), mnist_train.__len__())\n",
        "mnist_test.__getitem__(0)[0].size(), mnist_test.__len__()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28]) 60000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 28, 28]), 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u08VF2biE41Q"
      },
      "source": [
        "### 3) Set DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PpP7pyTE41R"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(mnist_train,batch_size=batch_size, shuffle=True,num_workers=2,drop_last=True)\n",
        "test_loader = torch.utils.data.DataLoader(mnist_test,batch_size=batch_size, shuffle=False,num_workers=2,drop_last=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9_keUAlE41S"
      },
      "source": [
        "## 3. Model & Optimizer\n",
        "\n",
        "### 1) CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBKru3x3E41U"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN,self).__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Conv2d(1,16,3,padding=1),  # 28 x 28\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16,32,3,padding=1), # 28 x 28\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2,2),            # 14 x 14\n",
        "            nn.Conv2d(32,64,3,padding=1), # 14 x 14\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2,2)             #  7 x 7\n",
        "        )\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Linear(64*7*7,100),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(100,10)\n",
        "        )       \n",
        "        \n",
        "    def forward(self,x):\n",
        "        out = self.layer(x)\n",
        "        out = out.view(batch_size,-1)\n",
        "        out = self.fc_layer(out)\n",
        "        return out"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfSDRzAqE41Y"
      },
      "source": [
        "### 2) Loss func & Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qev-ZYS8E41Z",
        "outputId": "feb754e0-19ad-4fdd-d846-ff34e3adf728",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "model = CNN().to(device)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "# 정형화는 weight_decay로 줄 수 있습니다.\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=0.1) #==> weight_decay ==> weight_regularization"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97_PWaomE41d"
      },
      "source": [
        "## 4. Train "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzrULCHKE41d",
        "outputId": "e6b866cb-b40d-4b4f-d681-a3a0cf9ac2e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for i in range(num_epoch):\n",
        "    for j,[image,label] in enumerate(train_loader):\n",
        "        x = image.to(device)\n",
        "        y_= label.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        output = model.forward(x)\n",
        "        loss = loss_func(output,y_)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "    if i % 10 == 0:\n",
        "        print(loss)          "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.3116, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJMcgjmSE41h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e1c8773-fb10-4140-d2b6-5eb25cd32bf0"
      },
      "source": [
        "param_list = list(model.parameters())\n",
        "print(param_list)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([[[[ 0.3172,  0.1493,  0.1448],\n",
            "          [ 0.2709,  0.0267,  0.0459],\n",
            "          [-0.1938,  0.2383, -0.2284]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2079, -0.0940, -0.0869],\n",
            "          [-0.0885, -0.2786,  0.1699],\n",
            "          [ 0.2008, -0.3180,  0.1161]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1323, -0.1896,  0.0920],\n",
            "          [-0.2731, -0.2385, -0.2633],\n",
            "          [-0.2280, -0.1860, -0.2539]]],\n",
            "\n",
            "\n",
            "        [[[-0.2300,  0.1232, -0.1815],\n",
            "          [-0.2030, -0.0852,  0.1175],\n",
            "          [-0.1707, -0.1044,  0.1873]]],\n",
            "\n",
            "\n",
            "        [[[-0.1605,  0.3062,  0.0791],\n",
            "          [ 0.0794,  0.1429,  0.1589],\n",
            "          [-0.0321,  0.1616,  0.1737]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0981, -0.0520, -0.0936],\n",
            "          [-0.2720, -0.1416,  0.3103],\n",
            "          [ 0.1587, -0.2344, -0.0570]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0821,  0.2333, -0.0171],\n",
            "          [ 0.2988,  0.2303,  0.1808],\n",
            "          [-0.2048, -0.2305, -0.2287]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0273, -0.0383,  0.2402],\n",
            "          [-0.1951, -0.2679,  0.1215],\n",
            "          [ 0.2135, -0.3055, -0.0791]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2400, -0.0599,  0.1259],\n",
            "          [ 0.0163, -0.1278,  0.0141],\n",
            "          [ 0.1545,  0.0576,  0.1775]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3101,  0.2593, -0.2490],\n",
            "          [ 0.1861, -0.0033,  0.0534],\n",
            "          [ 0.0394,  0.2799,  0.1075]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0804,  0.0146, -0.0947],\n",
            "          [ 0.2061,  0.1101,  0.1406],\n",
            "          [ 0.0248, -0.0144,  0.2475]]],\n",
            "\n",
            "\n",
            "        [[[-0.1251,  0.1243, -0.1974],\n",
            "          [ 0.0783,  0.2667,  0.2051],\n",
            "          [-0.0653, -0.2759, -0.2481]]],\n",
            "\n",
            "\n",
            "        [[[-0.2583,  0.1252,  0.2695],\n",
            "          [-0.0790, -0.1528, -0.1095],\n",
            "          [ 0.1575,  0.1773,  0.0773]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3125, -0.2758, -0.1307],\n",
            "          [ 0.3118, -0.0207,  0.1120],\n",
            "          [ 0.2936, -0.1972, -0.0328]]],\n",
            "\n",
            "\n",
            "        [[[-0.0727,  0.1090, -0.2039],\n",
            "          [ 0.1019, -0.2680,  0.2263],\n",
            "          [-0.0907, -0.2269,  0.1813]]],\n",
            "\n",
            "\n",
            "        [[[-0.2313,  0.3171, -0.1379],\n",
            "          [-0.1049,  0.0150,  0.0804],\n",
            "          [ 0.0422, -0.1682,  0.0751]]]], device='cuda:0', requires_grad=True), Parameter containing:\n",
            "tensor([-0.1520,  0.2180, -0.2512,  0.0551,  0.0605, -0.1410, -0.1612,  0.0900,\n",
            "        -0.0472, -0.1626,  0.1390,  0.0646, -0.0831,  0.1110, -0.1527, -0.2145],\n",
            "       device='cuda:0', requires_grad=True), Parameter containing:\n",
            "tensor([[[[-0.0328,  0.0018, -0.0178],\n",
            "          [ 0.0186,  0.0763,  0.0022],\n",
            "          [-0.0595, -0.0545,  0.0449]],\n",
            "\n",
            "         [[-0.0568, -0.0170,  0.0011],\n",
            "          [ 0.0349,  0.0103, -0.0145],\n",
            "          [-0.0330, -0.0082,  0.0589]],\n",
            "\n",
            "         [[ 0.0562, -0.0102, -0.0239],\n",
            "          [ 0.0592, -0.0561,  0.0696],\n",
            "          [ 0.0267, -0.0741, -0.0204]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0024,  0.0776, -0.0656],\n",
            "          [ 0.0082,  0.0030,  0.0337],\n",
            "          [-0.0616,  0.0710, -0.0450]],\n",
            "\n",
            "         [[ 0.0191, -0.0683, -0.0670],\n",
            "          [ 0.0064, -0.0671, -0.0141],\n",
            "          [ 0.0695, -0.0544,  0.0275]],\n",
            "\n",
            "         [[-0.0046, -0.0080, -0.0735],\n",
            "          [ 0.0175,  0.0158,  0.0287],\n",
            "          [ 0.0559,  0.0494,  0.0232]]],\n",
            "\n",
            "\n",
            "        [[[-0.0252,  0.0724, -0.0406],\n",
            "          [-0.0215,  0.0040, -0.0229],\n",
            "          [ 0.0782,  0.0037,  0.0570]],\n",
            "\n",
            "         [[-0.0453,  0.0589, -0.0253],\n",
            "          [ 0.0743, -0.0249,  0.0062],\n",
            "          [ 0.0353, -0.0135,  0.0301]],\n",
            "\n",
            "         [[-0.0408, -0.0727, -0.0149],\n",
            "          [-0.0680,  0.0131,  0.0781],\n",
            "          [ 0.0387, -0.0356,  0.0602]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0492,  0.0163, -0.0598],\n",
            "          [ 0.0569,  0.0381,  0.0291],\n",
            "          [ 0.0632, -0.0347, -0.0559]],\n",
            "\n",
            "         [[ 0.0712, -0.0119, -0.0562],\n",
            "          [-0.0483,  0.0068, -0.0764],\n",
            "          [ 0.0196, -0.0742,  0.0016]],\n",
            "\n",
            "         [[ 0.0684, -0.0646, -0.0588],\n",
            "          [-0.0192, -0.0230, -0.0683],\n",
            "          [-0.0768,  0.0225,  0.0289]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0018,  0.0451, -0.0137],\n",
            "          [-0.0042, -0.0191, -0.0085],\n",
            "          [ 0.0639, -0.0385,  0.0153]],\n",
            "\n",
            "         [[ 0.0429, -0.0163,  0.0085],\n",
            "          [-0.0560, -0.0607,  0.0005],\n",
            "          [ 0.0771,  0.0659,  0.0519]],\n",
            "\n",
            "         [[ 0.0618,  0.0046,  0.0624],\n",
            "          [-0.0157, -0.0214, -0.0147],\n",
            "          [ 0.0114,  0.0266, -0.0386]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0477,  0.0155,  0.0521],\n",
            "          [ 0.0229, -0.0422, -0.0604],\n",
            "          [ 0.0340,  0.0546, -0.0504]],\n",
            "\n",
            "         [[ 0.0527, -0.0598, -0.0317],\n",
            "          [ 0.0484, -0.0048, -0.0309],\n",
            "          [-0.0333,  0.0430, -0.0385]],\n",
            "\n",
            "         [[ 0.0165, -0.0185, -0.0192],\n",
            "          [ 0.0621, -0.0412,  0.0365],\n",
            "          [ 0.0479, -0.0218, -0.0626]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0684, -0.0512,  0.0424],\n",
            "          [ 0.0340, -0.0693,  0.0493],\n",
            "          [ 0.0734,  0.0681, -0.0228]],\n",
            "\n",
            "         [[-0.0639,  0.0406,  0.0647],\n",
            "          [-0.0578,  0.0151,  0.0162],\n",
            "          [ 0.0004, -0.0244, -0.0054]],\n",
            "\n",
            "         [[-0.0072,  0.0152, -0.0194],\n",
            "          [-0.0498, -0.0402,  0.0411],\n",
            "          [ 0.0423, -0.0206,  0.0031]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0653,  0.0358,  0.0535],\n",
            "          [ 0.0713,  0.0535, -0.0319],\n",
            "          [-0.0673, -0.0406, -0.0646]],\n",
            "\n",
            "         [[-0.0270,  0.0005, -0.0712],\n",
            "          [ 0.0216,  0.0337, -0.0377],\n",
            "          [ 0.0638, -0.0013, -0.0479]],\n",
            "\n",
            "         [[-0.0043, -0.0043, -0.0423],\n",
            "          [ 0.0525, -0.0006, -0.0743],\n",
            "          [ 0.0143,  0.0372,  0.0006]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0039,  0.0501, -0.0101],\n",
            "          [-0.0205,  0.0355,  0.0686],\n",
            "          [-0.0114, -0.0111,  0.0058]],\n",
            "\n",
            "         [[-0.0638,  0.0707,  0.0398],\n",
            "          [-0.0654,  0.0644,  0.0026],\n",
            "          [ 0.0654,  0.0515, -0.0331]],\n",
            "\n",
            "         [[ 0.0482,  0.0237,  0.0079],\n",
            "          [ 0.0747, -0.0024, -0.0136],\n",
            "          [-0.0488,  0.0578, -0.0224]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0421,  0.0098,  0.0345],\n",
            "          [ 0.0246,  0.0234,  0.0228],\n",
            "          [-0.0287,  0.0437, -0.0659]],\n",
            "\n",
            "         [[-0.0635, -0.0236, -0.0397],\n",
            "          [ 0.0108, -0.0535, -0.0332],\n",
            "          [-0.0441,  0.0231,  0.0195]],\n",
            "\n",
            "         [[ 0.0485,  0.0744, -0.0417],\n",
            "          [ 0.0776,  0.0140, -0.0314],\n",
            "          [-0.0607, -0.0124, -0.0718]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0439, -0.0668,  0.0035],\n",
            "          [-0.0437, -0.0071, -0.0325],\n",
            "          [ 0.0058, -0.0614,  0.0177]],\n",
            "\n",
            "         [[ 0.0308,  0.0033, -0.0319],\n",
            "          [-0.0455,  0.0674,  0.0540],\n",
            "          [ 0.0152,  0.0708,  0.0726]],\n",
            "\n",
            "         [[ 0.0248, -0.0699,  0.0326],\n",
            "          [ 0.0591, -0.0360,  0.0079],\n",
            "          [-0.0635, -0.0374,  0.0355]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0183,  0.0112,  0.0586],\n",
            "          [ 0.0324,  0.0505, -0.0550],\n",
            "          [ 0.0420,  0.0655,  0.0690]],\n",
            "\n",
            "         [[-0.0538,  0.0756,  0.0502],\n",
            "          [ 0.0529,  0.0022,  0.0325],\n",
            "          [-0.0750,  0.0090, -0.0719]],\n",
            "\n",
            "         [[-0.0634, -0.0670, -0.0397],\n",
            "          [-0.0435, -0.0668, -0.0659],\n",
            "          [ 0.0696,  0.0252,  0.0289]]]], device='cuda:0', requires_grad=True), Parameter containing:\n",
            "tensor([-0.0096, -0.0590, -0.0181,  0.0307, -0.0271, -0.0438,  0.0396,  0.0627,\n",
            "        -0.0774, -0.0175,  0.0757, -0.0702,  0.0232,  0.0262, -0.0394, -0.0132,\n",
            "         0.0474, -0.0504,  0.0208,  0.0126,  0.0781, -0.0590, -0.0508,  0.0631,\n",
            "         0.0110,  0.0294, -0.0549, -0.0538, -0.0187, -0.0026,  0.0564, -0.0667],\n",
            "       device='cuda:0', requires_grad=True), Parameter containing:\n",
            "tensor([[[[-5.1726e-02, -3.9251e-02,  1.1730e-02],\n",
            "          [ 3.3504e-02,  2.1524e-02,  5.0417e-02],\n",
            "          [ 1.0961e-02,  3.0341e-02, -4.6836e-02]],\n",
            "\n",
            "         [[ 3.8085e-02, -1.2752e-02, -4.1539e-02],\n",
            "          [-1.9991e-02,  2.7033e-02, -2.9476e-02],\n",
            "          [-4.5013e-02, -3.2961e-02,  1.5862e-02]],\n",
            "\n",
            "         [[ 1.9839e-02, -2.5043e-02, -1.2749e-03],\n",
            "          [ 6.5647e-04, -1.1140e-02, -7.2244e-03],\n",
            "          [-1.3796e-02, -5.0813e-02,  3.1734e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.4054e-02, -2.7583e-02, -4.8481e-02],\n",
            "          [ 2.0348e-02, -1.2562e-04,  6.9345e-03],\n",
            "          [-2.3550e-02,  3.9911e-02, -2.3150e-03]],\n",
            "\n",
            "         [[-4.1436e-02, -1.7893e-02, -4.2967e-02],\n",
            "          [ 9.9256e-03, -4.1748e-02, -1.7451e-02],\n",
            "          [-4.5779e-02, -3.8502e-02, -5.4715e-02]],\n",
            "\n",
            "         [[ 9.3708e-04,  7.8479e-03, -5.5709e-02],\n",
            "          [-2.8497e-02, -4.6778e-02, -2.9979e-02],\n",
            "          [-4.1133e-02,  2.7864e-02, -8.8249e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4694e-02,  1.8761e-02,  3.7293e-02],\n",
            "          [ 5.6034e-02,  4.1944e-02,  3.8956e-02],\n",
            "          [ 5.4720e-02,  2.2037e-02,  1.3077e-02]],\n",
            "\n",
            "         [[ 1.6310e-02, -5.6551e-03, -2.5325e-02],\n",
            "          [-1.5304e-02,  7.2791e-03,  4.6695e-02],\n",
            "          [-1.5591e-02,  5.1931e-02,  5.6234e-02]],\n",
            "\n",
            "         [[-1.2823e-02, -4.4473e-03,  2.9994e-02],\n",
            "          [-2.3282e-02,  1.3950e-02, -8.2111e-03],\n",
            "          [-8.3287e-03, -1.3879e-02, -2.4182e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.1144e-02, -3.3070e-02,  3.5520e-02],\n",
            "          [-3.4889e-02, -4.4132e-02,  5.1916e-02],\n",
            "          [-2.4603e-02, -6.6773e-03, -4.0754e-02]],\n",
            "\n",
            "         [[ 5.1155e-02,  4.0264e-02, -3.0016e-02],\n",
            "          [ 3.3646e-02, -4.5329e-02,  2.2491e-03],\n",
            "          [-9.6039e-03, -3.9774e-02, -1.2891e-02]],\n",
            "\n",
            "         [[ 5.0431e-02,  3.9067e-02, -3.2681e-02],\n",
            "          [-5.3759e-02,  1.1341e-02,  1.4487e-02],\n",
            "          [-2.4363e-02,  5.0727e-02, -2.4160e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 3.3604e-02,  2.5733e-02, -1.7363e-02],\n",
            "          [ 5.0434e-02, -3.0165e-02,  2.4078e-03],\n",
            "          [ 4.2614e-02,  2.8854e-02, -5.3588e-02]],\n",
            "\n",
            "         [[-4.8278e-02,  1.8019e-03, -4.2829e-02],\n",
            "          [-2.5744e-02, -2.0436e-02,  5.9321e-04],\n",
            "          [ 7.2125e-03, -4.7640e-02, -2.3673e-02]],\n",
            "\n",
            "         [[ 1.0496e-02, -1.9639e-02,  1.4494e-02],\n",
            "          [ 1.0876e-02,  2.9800e-02,  4.3614e-02],\n",
            "          [ 3.2169e-02, -5.4146e-02,  1.5277e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.1616e-02, -1.3270e-02, -1.9605e-02],\n",
            "          [-5.5626e-02, -2.4681e-02,  3.7797e-02],\n",
            "          [ 3.3101e-02, -2.7030e-02, -4.4305e-02]],\n",
            "\n",
            "         [[ 2.3907e-02, -1.8072e-02,  4.4313e-02],\n",
            "          [ 5.6219e-03, -3.5074e-02,  1.1291e-02],\n",
            "          [ 1.7485e-02,  2.3958e-02,  8.0542e-03]],\n",
            "\n",
            "         [[-7.0151e-03, -1.3064e-02, -2.7172e-02],\n",
            "          [ 1.4939e-02, -4.4599e-02, -1.7544e-02],\n",
            "          [ 3.5142e-02,  1.2925e-02, -2.3611e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 5.6996e-03,  1.1526e-02, -4.8082e-02],\n",
            "          [-5.5621e-02, -2.8035e-02, -2.4496e-02],\n",
            "          [-1.5562e-02,  4.0780e-02,  4.8343e-02]],\n",
            "\n",
            "         [[ 1.2318e-02,  4.4294e-02,  3.9042e-02],\n",
            "          [-2.5813e-02,  8.7743e-03,  2.1384e-02],\n",
            "          [ 8.0019e-03,  2.3949e-02, -1.6413e-02]],\n",
            "\n",
            "         [[ 1.4731e-02, -1.7409e-02,  1.2411e-02],\n",
            "          [-5.3299e-02, -9.4512e-05, -1.6209e-03],\n",
            "          [-1.7619e-02, -2.3704e-02, -1.0064e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.0093e-02,  4.9278e-02,  3.4465e-02],\n",
            "          [ 2.9100e-02,  4.8619e-02,  3.0822e-02],\n",
            "          [ 5.2404e-02, -4.1269e-02, -9.6442e-03]],\n",
            "\n",
            "         [[ 6.6926e-03,  3.6827e-02, -4.0569e-02],\n",
            "          [-2.5465e-02,  2.2847e-03,  2.0170e-02],\n",
            "          [-3.2684e-03, -3.4334e-02,  3.5266e-02]],\n",
            "\n",
            "         [[ 3.5967e-02, -3.3707e-02, -1.1569e-03],\n",
            "          [ 5.2045e-03, -4.3758e-02,  2.0721e-02],\n",
            "          [-2.1389e-02,  2.4009e-02, -2.9692e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 5.0043e-02,  2.0296e-02,  4.2940e-02],\n",
            "          [-2.0017e-02, -1.3662e-02,  4.5889e-02],\n",
            "          [ 8.1032e-03, -3.2187e-02, -4.2073e-02]],\n",
            "\n",
            "         [[ 5.2619e-02,  8.6118e-03, -3.6270e-02],\n",
            "          [-5.4634e-02, -2.4521e-03, -1.8726e-02],\n",
            "          [-3.3339e-02,  3.3651e-02,  3.7707e-02]],\n",
            "\n",
            "         [[-4.2770e-02, -4.5571e-02,  4.2749e-02],\n",
            "          [ 2.6825e-02,  2.1400e-02,  6.8289e-03],\n",
            "          [ 4.2789e-02,  1.0869e-02,  2.0783e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.2945e-02, -4.1104e-02,  4.9362e-02],\n",
            "          [-5.1263e-02, -3.1949e-02,  4.3123e-02],\n",
            "          [ 1.6468e-02,  1.2421e-02, -3.7081e-02]],\n",
            "\n",
            "         [[ 4.3528e-02, -4.3310e-02, -1.8521e-02],\n",
            "          [ 3.4694e-02,  6.3487e-03, -4.1787e-03],\n",
            "          [ 2.9826e-02,  2.9301e-02, -3.4844e-02]],\n",
            "\n",
            "         [[-3.3474e-02,  3.3408e-02,  4.9216e-02],\n",
            "          [-4.7359e-02,  1.2990e-02, -3.9612e-02],\n",
            "          [ 4.4614e-02, -6.8909e-03, -3.9155e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.5425e-02,  3.1222e-02, -6.9640e-03],\n",
            "          [-4.8327e-02, -2.2105e-02, -3.5176e-02],\n",
            "          [-3.3551e-02, -2.0437e-02, -2.6326e-02]],\n",
            "\n",
            "         [[-7.2156e-03, -2.0267e-02,  2.2425e-02],\n",
            "          [-3.2072e-03,  4.8599e-02, -3.2233e-02],\n",
            "          [-5.0097e-02,  3.3016e-02,  4.1353e-02]],\n",
            "\n",
            "         [[ 5.4345e-02,  5.3466e-03,  1.9491e-02],\n",
            "          [-4.4251e-02, -4.9897e-02, -3.9526e-02],\n",
            "          [ 4.7565e-02,  3.4886e-04, -1.2728e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.3159e-02, -1.9565e-02,  3.9585e-02],\n",
            "          [-1.1068e-02, -7.7993e-03, -2.1830e-02],\n",
            "          [-2.0082e-02,  3.1767e-03,  5.3175e-02]],\n",
            "\n",
            "         [[ 4.0507e-02, -2.7479e-02, -4.4754e-02],\n",
            "          [-4.3633e-02,  2.9450e-02, -1.1503e-02],\n",
            "          [ 2.7301e-02, -3.9962e-03,  8.1710e-03]],\n",
            "\n",
            "         [[ 4.9545e-02,  4.6040e-02, -3.1781e-03],\n",
            "          [-2.1569e-02, -2.6858e-03,  2.1487e-02],\n",
            "          [ 1.6963e-03, -3.2233e-02,  1.3082e-02]]]], device='cuda:0',\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([-0.0253,  0.0523, -0.0407, -0.0499, -0.0535,  0.0114,  0.0345, -0.0320,\n",
            "        -0.0002,  0.0232, -0.0056, -0.0500, -0.0346,  0.0180, -0.0397, -0.0196,\n",
            "        -0.0387,  0.0471,  0.0242, -0.0123, -0.0105,  0.0427, -0.0047,  0.0542,\n",
            "         0.0316, -0.0327, -0.0284,  0.0375, -0.0331,  0.0371, -0.0320, -0.0355,\n",
            "         0.0192,  0.0464, -0.0208, -0.0188,  0.0218, -0.0388,  0.0400, -0.0209,\n",
            "        -0.0537,  0.0293, -0.0312, -0.0070,  0.0186, -0.0295, -0.0234, -0.0553,\n",
            "        -0.0195,  0.0471, -0.0034, -0.0310,  0.0161, -0.0190, -0.0292, -0.0317,\n",
            "        -0.0010, -0.0201, -0.0385, -0.0073, -0.0155,  0.0249,  0.0245, -0.0223],\n",
            "       device='cuda:0', requires_grad=True), Parameter containing:\n",
            "tensor([[ 9.7422e-03,  6.9778e-03, -5.8807e-03,  ..., -1.2341e-02,\n",
            "          1.8469e-03,  1.1821e-02],\n",
            "        [ 1.2598e-02, -1.0567e-02,  1.6276e-02,  ..., -8.3037e-03,\n",
            "          2.6126e-03, -9.1624e-03],\n",
            "        [ 1.1169e-02,  8.6829e-03, -4.3139e-03,  ..., -9.2499e-03,\n",
            "         -3.3365e-05,  5.5274e-03],\n",
            "        ...,\n",
            "        [-7.2118e-03,  1.4146e-02,  1.2314e-02,  ...,  8.4760e-03,\n",
            "         -9.6439e-03,  1.2666e-02],\n",
            "        [ 1.6373e-02,  9.6914e-03, -1.1323e-03,  ..., -2.3405e-03,\n",
            "         -9.9905e-03, -1.0867e-02],\n",
            "        [ 7.5562e-03,  8.2099e-03, -2.9558e-03,  ...,  1.1415e-02,\n",
            "          1.1317e-02,  8.1623e-03]], device='cuda:0', requires_grad=True), Parameter containing:\n",
            "tensor([-4.8451e-03, -6.9593e-03, -1.2693e-02,  1.5480e-02,  7.8008e-03,\n",
            "        -1.3251e-02,  1.1539e-02,  3.0848e-05,  2.1192e-03, -1.3039e-02,\n",
            "        -1.2902e-02, -1.7084e-02, -7.6354e-03,  8.2058e-03, -1.3412e-02,\n",
            "        -1.0516e-02,  1.2607e-02,  1.3318e-02, -1.1391e-02,  4.4066e-03,\n",
            "         1.2615e-02, -8.9459e-03,  2.0788e-03,  3.3996e-03, -4.6007e-03,\n",
            "        -5.5636e-03, -4.9610e-03,  9.0283e-03,  4.6176e-03, -8.9351e-03,\n",
            "        -8.9889e-03, -4.7067e-03, -1.4943e-02,  8.4351e-03, -7.6586e-03,\n",
            "         3.1918e-03,  5.9481e-03,  1.3226e-02, -8.4665e-03, -2.3046e-03,\n",
            "         4.9496e-03, -8.6185e-03, -2.9942e-03, -9.0892e-04, -5.0076e-03,\n",
            "         5.6375e-03, -1.3077e-02, -6.3555e-03, -1.5812e-02,  1.1181e-02,\n",
            "        -1.0342e-02,  1.4942e-02,  8.5070e-03, -1.1568e-02,  6.7547e-04,\n",
            "        -8.6261e-03,  1.1865e-02, -3.8856e-03,  1.5425e-02,  1.2499e-03,\n",
            "        -1.4596e-02,  1.1140e-03,  1.0320e-02, -1.5590e-02,  1.0109e-02,\n",
            "        -1.0784e-02, -8.8994e-03, -1.6330e-02,  9.1982e-04,  1.2337e-02,\n",
            "        -1.6874e-02, -1.6929e-02,  8.7832e-03,  1.0186e-02,  5.2509e-03,\n",
            "         2.1909e-03,  5.7375e-03,  4.4282e-03, -1.0626e-02,  5.3473e-03,\n",
            "         8.4926e-03, -1.4276e-02, -4.7745e-03,  2.6213e-03,  1.1337e-02,\n",
            "        -1.2675e-02,  1.4144e-03, -2.3306e-03,  1.9116e-04, -7.2144e-03,\n",
            "         1.3018e-02,  1.3602e-02,  4.0831e-03,  6.5568e-04,  6.6228e-03,\n",
            "        -6.7824e-03, -1.3639e-02, -6.1697e-03, -1.1970e-02,  1.2737e-02],\n",
            "       device='cuda:0', requires_grad=True), Parameter containing:\n",
            "tensor([[-7.5032e-02,  8.8910e-02, -2.1264e-02, -4.0609e-03,  6.0677e-02,\n",
            "          8.3813e-02, -4.6316e-02, -6.5033e-02, -5.7099e-02, -4.6060e-02,\n",
            "          9.0472e-02,  3.8366e-02,  6.9105e-02, -9.5771e-03, -7.0355e-02,\n",
            "          2.9491e-02, -7.1273e-02,  6.9938e-02,  4.6781e-03,  5.1692e-02,\n",
            "         -3.2844e-02,  7.8760e-02,  1.1266e-02,  6.7777e-02, -7.3347e-02,\n",
            "         -6.1842e-04,  4.7915e-02,  3.2740e-02,  5.9755e-02,  1.5361e-02,\n",
            "         -2.4178e-03, -6.5387e-02, -2.7089e-03,  7.3170e-02, -3.0263e-02,\n",
            "         -5.4006e-02, -4.2340e-02, -8.0816e-02,  5.9951e-02, -8.8991e-02,\n",
            "         -6.7944e-02,  9.1357e-02, -1.9397e-02, -2.9548e-02, -2.0103e-02,\n",
            "          5.2453e-02, -4.5305e-02,  2.2703e-02,  2.2501e-02,  3.2146e-02,\n",
            "         -5.7278e-02,  5.1040e-02,  6.3836e-02,  6.1424e-02,  1.7129e-02,\n",
            "         -1.5599e-02,  6.0455e-02,  2.4839e-02,  4.6099e-02, -1.6667e-02,\n",
            "          2.4804e-02,  6.8022e-02, -2.5067e-02,  9.3496e-02, -8.3564e-02,\n",
            "          2.5586e-02,  6.1231e-02,  2.0504e-02, -3.5050e-02,  2.8289e-02,\n",
            "          7.3568e-02,  5.3313e-02,  3.5929e-02, -2.8047e-02, -2.2314e-02,\n",
            "          6.5006e-02,  1.5890e-02,  4.2383e-02, -7.0169e-02,  1.7009e-02,\n",
            "         -6.7682e-02, -4.0850e-03,  3.8202e-02, -8.3611e-02,  8.0313e-02,\n",
            "          8.0640e-02,  4.1793e-02,  5.5663e-02, -8.5387e-02, -4.1064e-02,\n",
            "         -2.1938e-02, -7.2711e-02,  2.5984e-03,  5.9778e-02,  4.5186e-02,\n",
            "          8.8514e-02,  4.1442e-02, -2.4989e-02,  6.2628e-02,  9.9107e-03],\n",
            "        [ 1.1417e-02, -8.5480e-02, -2.4121e-02, -7.7950e-02, -2.4469e-02,\n",
            "         -7.3426e-02,  1.6197e-02,  4.8298e-02, -3.6789e-02, -1.1069e-02,\n",
            "         -3.1498e-02, -1.3217e-02,  2.7805e-02, -1.1141e-02, -4.4683e-02,\n",
            "          3.4379e-03, -3.5196e-02,  3.9313e-02,  3.5267e-02, -6.4530e-02,\n",
            "         -3.0490e-02, -9.3796e-02,  2.8733e-02, -2.5631e-02, -8.8517e-02,\n",
            "         -7.4375e-02,  9.2367e-02,  1.5443e-02,  5.5398e-02, -3.5878e-02,\n",
            "         -2.1336e-02,  5.0712e-02,  5.0325e-02,  4.5875e-02, -9.4927e-02,\n",
            "          2.3593e-02, -4.1143e-02,  5.9256e-02, -2.6788e-02, -7.5501e-02,\n",
            "          6.2075e-03, -9.9058e-03, -3.1694e-02, -5.0184e-02, -7.1323e-02,\n",
            "         -8.5696e-02,  5.0932e-02,  8.0901e-02, -5.7896e-02, -7.2100e-02,\n",
            "          2.5996e-03, -9.2208e-02,  1.8943e-02,  8.5536e-02, -4.5539e-03,\n",
            "         -3.6270e-03,  7.8383e-02,  9.6753e-03, -5.3989e-02, -3.8634e-02,\n",
            "          7.0795e-02, -8.5117e-05, -7.9432e-02, -1.1216e-02,  6.2515e-02,\n",
            "          5.3479e-02,  6.0094e-02, -8.6559e-02,  8.8515e-02, -2.6977e-02,\n",
            "          7.4650e-03, -4.3593e-02,  5.6282e-02, -8.1953e-02,  8.3042e-02,\n",
            "         -4.0589e-02,  5.6663e-02,  5.3080e-02, -2.3470e-03, -6.4074e-02,\n",
            "         -3.1773e-02, -2.7488e-02,  7.8920e-02, -8.2782e-03, -5.9165e-02,\n",
            "          6.0571e-02, -3.9816e-02, -3.0494e-02, -6.9745e-02,  1.7776e-02,\n",
            "         -4.0047e-03, -8.5431e-02, -6.7894e-02, -6.5806e-02, -8.6467e-02,\n",
            "          5.7016e-02,  3.4603e-02, -6.0143e-02, -5.4520e-02,  2.3607e-02],\n",
            "        [ 8.4477e-04,  4.1977e-02, -5.4545e-03, -1.7993e-03,  5.5322e-02,\n",
            "         -1.0405e-02,  7.4091e-02, -1.5263e-02, -3.3662e-02, -8.8319e-02,\n",
            "          3.1810e-02,  6.3864e-02, -6.3947e-02,  7.9635e-02,  4.5971e-03,\n",
            "          1.7361e-02, -7.6924e-02,  6.4758e-02, -6.5254e-02, -5.0393e-02,\n",
            "          1.0846e-02, -1.5238e-02, -3.5589e-02, -3.0961e-02, -8.7009e-02,\n",
            "         -3.3103e-02,  1.2835e-02, -5.3369e-02, -8.2802e-02, -7.5297e-02,\n",
            "         -2.6340e-02,  7.3486e-02, -4.2415e-02,  1.2624e-02,  7.9039e-02,\n",
            "         -1.6028e-02,  3.1236e-02,  1.7155e-02,  3.2565e-02, -4.6104e-02,\n",
            "          1.9124e-02,  4.3352e-02,  8.5072e-02,  8.1303e-02, -3.4346e-02,\n",
            "         -3.0235e-02,  9.3790e-02, -7.1215e-02,  1.2215e-02, -2.9426e-02,\n",
            "         -4.7649e-02,  8.5181e-02, -5.9875e-02, -3.9060e-02,  5.4474e-02,\n",
            "         -3.3320e-02,  6.6339e-02,  7.6022e-02, -2.1014e-02, -7.1336e-02,\n",
            "          8.4793e-02,  7.1315e-02,  7.1372e-02,  5.0809e-02, -4.7929e-02,\n",
            "         -5.1832e-02,  8.6248e-02,  2.0891e-02,  9.0446e-02, -8.9001e-02,\n",
            "          1.6222e-02, -7.4413e-02, -8.6514e-02,  2.2220e-02,  9.3909e-02,\n",
            "          5.8417e-03,  2.8732e-02, -1.2375e-02,  3.3668e-02,  5.8276e-02,\n",
            "         -3.2157e-02, -3.5918e-02,  6.7340e-02,  5.7097e-02, -5.9034e-02,\n",
            "          4.8548e-02,  7.3669e-02,  7.5276e-02,  1.2770e-02,  7.7137e-02,\n",
            "         -1.5858e-02,  3.8341e-02,  2.4669e-02, -4.0511e-02, -3.8343e-02,\n",
            "          6.1832e-02, -4.1159e-02, -1.8433e-02,  8.0363e-02,  5.8605e-02],\n",
            "        [-3.2383e-02, -1.5787e-02,  4.8345e-02,  3.2612e-02,  4.2234e-02,\n",
            "         -5.1963e-03, -6.8687e-02, -2.5910e-02, -8.0990e-02,  6.5646e-02,\n",
            "          1.0492e-02, -3.3694e-02, -5.1821e-03, -1.5607e-02,  4.9485e-02,\n",
            "         -1.0094e-02, -3.8704e-02,  7.0347e-02, -6.5672e-02, -6.8992e-03,\n",
            "          7.3229e-02,  4.6020e-02,  2.6753e-02, -2.8068e-02,  3.3010e-02,\n",
            "          1.7229e-02, -5.9727e-02,  6.7083e-02,  6.9349e-05, -9.1346e-02,\n",
            "          8.1653e-02, -6.7687e-02,  6.4146e-02, -6.4971e-02,  2.6783e-02,\n",
            "         -8.7873e-02, -3.6698e-02, -2.1619e-02,  6.0302e-02,  5.6003e-02,\n",
            "         -8.6426e-02,  7.1005e-02, -7.5884e-02,  3.7308e-02, -3.9076e-02,\n",
            "          9.0755e-02,  5.4992e-02,  4.8847e-02,  3.0651e-02, -5.3398e-02,\n",
            "          6.9174e-02,  8.7237e-02, -8.4696e-02,  5.8505e-02, -6.0711e-02,\n",
            "         -1.4576e-02,  9.7195e-03,  5.2986e-02, -7.2989e-02, -2.1910e-02,\n",
            "         -3.6261e-02,  4.2895e-02,  3.2815e-02,  7.3587e-02, -1.3606e-02,\n",
            "         -9.4996e-02, -1.2138e-02,  4.2717e-03,  7.7928e-02,  2.0436e-02,\n",
            "          2.9994e-02, -5.1740e-02, -4.8426e-03,  9.5559e-02,  8.7614e-02,\n",
            "         -2.1831e-02,  4.9407e-02, -3.2791e-02, -5.5752e-02, -7.1505e-02,\n",
            "         -8.5419e-03,  1.1962e-02, -9.5012e-02, -9.1547e-02, -2.8279e-02,\n",
            "         -1.4380e-02, -9.0908e-02,  4.7511e-02, -5.1191e-02,  2.9237e-02,\n",
            "         -3.1897e-03, -4.9691e-03,  2.3844e-02,  4.9924e-02,  1.5163e-02,\n",
            "          2.0358e-02, -4.2320e-02, -1.5681e-02, -7.1225e-02,  8.7266e-02],\n",
            "        [ 7.9974e-02,  2.2233e-02,  1.8623e-02,  2.2446e-02, -2.1654e-02,\n",
            "         -3.0781e-02,  1.8464e-02,  4.1063e-02,  2.7573e-02, -6.1604e-03,\n",
            "         -3.6793e-02,  5.0953e-02, -2.1713e-02, -9.1050e-02,  1.5475e-02,\n",
            "          9.2075e-02, -5.1223e-02, -3.3416e-02,  4.1672e-02, -8.7104e-02,\n",
            "         -5.0623e-02,  2.4601e-02,  4.3351e-02, -5.2936e-03, -3.9878e-02,\n",
            "          8.4981e-02, -5.2495e-02,  4.8427e-02, -3.8545e-02,  1.4735e-02,\n",
            "          2.1190e-02,  3.0039e-03,  4.8214e-02,  5.6584e-02,  2.8577e-02,\n",
            "          4.8220e-02, -8.7584e-02, -3.1346e-03,  3.0434e-02, -2.1276e-02,\n",
            "          9.2397e-02,  1.8007e-02, -9.3247e-02,  5.8332e-02,  7.1613e-02,\n",
            "          1.7821e-02, -6.9445e-02,  8.4124e-02,  4.6813e-02, -9.0389e-02,\n",
            "         -6.0642e-02, -6.4342e-02, -1.2835e-02,  5.9196e-02, -8.8860e-02,\n",
            "          1.0387e-02, -7.6466e-02,  2.9129e-02, -1.8491e-02, -7.9520e-02,\n",
            "          3.5244e-02, -2.7643e-02,  8.5632e-02, -4.9120e-02,  4.0581e-03,\n",
            "          3.9162e-02, -1.2899e-02, -8.5955e-02, -4.3527e-02,  2.5291e-02,\n",
            "          6.7265e-02, -3.9866e-02,  6.9314e-02,  2.5328e-02, -7.9082e-02,\n",
            "         -1.0008e-02,  7.1022e-02,  8.1455e-02,  6.7750e-02,  6.6243e-02,\n",
            "          9.2692e-02,  5.3612e-02, -3.9769e-02, -3.2095e-02, -1.0391e-02,\n",
            "         -7.1847e-02,  8.3754e-02, -7.3612e-02,  1.2601e-02, -1.4545e-02,\n",
            "         -1.3816e-02, -8.8887e-02,  3.4429e-02,  4.1193e-02,  5.1950e-02,\n",
            "         -3.6797e-02,  7.1985e-03,  4.8788e-03,  7.8594e-02, -3.6219e-02],\n",
            "        [-5.3642e-02, -4.8286e-02, -5.6876e-02, -2.9200e-02, -9.4394e-04,\n",
            "          9.0549e-02,  7.8112e-02,  5.8790e-02, -8.0693e-02, -6.3676e-02,\n",
            "         -7.3226e-02, -1.8846e-02,  3.4911e-02, -6.3710e-02, -4.2077e-02,\n",
            "         -1.0030e-02,  3.6659e-02, -4.3493e-02, -9.1289e-02, -4.6333e-02,\n",
            "         -8.2948e-02, -5.2580e-02, -3.8207e-02, -6.9814e-02,  6.8776e-02,\n",
            "          6.2984e-02,  1.7965e-02, -9.2894e-02, -7.2843e-03,  8.6262e-02,\n",
            "         -4.4334e-02, -3.1989e-02, -4.6242e-02,  8.0398e-03, -3.6006e-02,\n",
            "          3.6674e-02,  3.9153e-02,  4.1992e-02, -2.2532e-02,  8.5277e-02,\n",
            "          5.3427e-02, -3.4210e-03,  5.5559e-02, -5.4130e-02, -3.3095e-02,\n",
            "          5.0660e-02,  3.9132e-02, -8.5557e-04, -8.1787e-02,  6.8271e-02,\n",
            "          5.4109e-02, -5.2954e-03,  8.0581e-02, -2.0927e-02,  6.6725e-02,\n",
            "          1.8137e-02,  6.2397e-02, -2.7843e-02, -4.4730e-02,  4.9108e-02,\n",
            "         -3.1605e-02, -7.8303e-02, -8.9648e-02,  8.9456e-02,  2.9318e-02,\n",
            "          2.7304e-02, -5.0757e-02,  7.4209e-02, -7.7124e-02, -5.7796e-02,\n",
            "         -8.1305e-02, -2.6589e-02, -2.8000e-02,  4.6384e-02, -8.6522e-02,\n",
            "         -2.4726e-02, -9.4773e-03,  1.7095e-02, -8.1853e-02,  7.7268e-02,\n",
            "          1.0644e-03, -5.0513e-02, -8.1259e-02,  3.6841e-02, -5.4942e-02,\n",
            "         -8.8422e-02, -4.6906e-03, -3.9290e-02,  3.4267e-02,  6.3729e-03,\n",
            "          8.6695e-02, -3.4693e-02, -5.1919e-02,  6.1787e-03,  2.1463e-02,\n",
            "          2.9428e-02,  7.4532e-02, -1.9176e-02,  5.5270e-02, -8.2301e-02],\n",
            "        [-2.0859e-02, -1.6312e-02, -9.0442e-02, -1.7521e-02,  1.4153e-02,\n",
            "         -8.4333e-02,  8.7327e-02, -5.3613e-02, -9.7266e-03,  2.6048e-02,\n",
            "         -3.9205e-02,  8.3005e-02,  2.3877e-02,  2.7885e-02, -3.0583e-02,\n",
            "         -1.0610e-02,  4.1587e-02,  7.7065e-02, -3.3804e-03, -5.7994e-02,\n",
            "         -3.8228e-02,  5.8676e-02, -3.5666e-02,  8.9942e-02,  3.2926e-02,\n",
            "         -6.6879e-02, -3.9073e-02, -8.5645e-02,  2.0405e-02,  3.8499e-02,\n",
            "          1.3562e-02,  9.1895e-02, -4.6269e-02,  7.0273e-02,  2.0449e-02,\n",
            "         -5.1932e-02,  8.9768e-02, -1.3919e-02,  8.8170e-02, -5.1929e-02,\n",
            "         -8.5161e-02,  3.2716e-02,  3.1720e-02,  6.9249e-02, -3.3871e-02,\n",
            "          3.0514e-02, -3.8149e-02, -9.0098e-02, -4.9432e-02, -5.5404e-02,\n",
            "          8.9936e-03,  5.9998e-02,  5.7041e-02,  7.6621e-02, -7.1404e-03,\n",
            "         -4.7185e-02, -6.3789e-02,  2.8447e-02, -4.9302e-02, -2.0019e-02,\n",
            "          1.9735e-02, -9.1040e-03, -2.5814e-02, -1.3623e-02,  7.0019e-02,\n",
            "         -4.9133e-02,  3.6971e-02, -4.2160e-02,  9.5601e-04, -3.8855e-02,\n",
            "          3.0900e-02,  4.1326e-04, -8.3126e-02, -1.0084e-04, -4.8154e-02,\n",
            "          2.9934e-02,  3.7087e-02, -3.3079e-02,  3.2668e-02, -2.5813e-02,\n",
            "         -2.5713e-02,  6.3031e-05,  6.4202e-02,  2.7850e-02, -7.6957e-03,\n",
            "          4.4418e-02, -2.5668e-02, -6.3371e-02,  4.7296e-02,  3.0096e-03,\n",
            "         -5.6369e-02,  6.4658e-02, -6.0004e-02, -3.4748e-02,  6.1354e-02,\n",
            "          4.6288e-02, -8.0391e-02, -4.6357e-02,  6.2625e-02,  4.5503e-02],\n",
            "        [-8.2846e-02, -4.0023e-02,  1.6025e-02, -9.4959e-02,  8.1008e-02,\n",
            "         -7.2015e-02,  3.7173e-02, -2.2793e-02,  9.4494e-03, -8.1258e-02,\n",
            "          6.5634e-02,  3.1386e-02,  4.2858e-02,  1.7374e-02,  6.5753e-02,\n",
            "          2.8642e-02, -9.3688e-03,  7.0110e-02, -2.6237e-02, -7.5270e-02,\n",
            "          2.7242e-02, -2.3957e-02,  1.4824e-02,  6.0728e-03,  4.8398e-02,\n",
            "          3.6638e-02, -8.6549e-02,  6.1119e-02, -5.3192e-02,  5.7883e-02,\n",
            "          7.8456e-03,  1.5376e-02, -7.1292e-03, -5.3326e-02,  4.5722e-02,\n",
            "          6.3254e-02,  1.7881e-02, -1.8130e-03, -4.6716e-02, -2.4922e-02,\n",
            "         -4.0595e-03, -4.4685e-02, -1.7558e-02,  1.9289e-02,  1.2944e-02,\n",
            "         -9.1945e-02,  8.4109e-02,  5.6111e-02,  1.2658e-02, -5.2387e-03,\n",
            "          8.3877e-02, -8.0081e-04,  8.6837e-02,  8.3476e-03, -3.0806e-02,\n",
            "         -5.8218e-02,  8.2212e-03,  1.8970e-02,  5.5601e-02, -5.9519e-02,\n",
            "          5.4227e-02, -6.4786e-02,  4.6425e-02,  1.1471e-02,  2.3468e-03,\n",
            "         -4.1441e-02,  7.7365e-02,  3.1843e-02, -4.9621e-02, -6.7897e-02,\n",
            "          6.4784e-02,  7.2763e-02, -1.7819e-02,  6.1760e-03,  4.1364e-03,\n",
            "          6.1350e-02, -5.6908e-02, -8.7074e-02, -8.2332e-02, -8.6753e-02,\n",
            "          3.4210e-03,  3.4505e-02, -6.2194e-02,  4.0259e-02,  5.2909e-03,\n",
            "          4.1325e-02, -4.1479e-02, -6.3871e-02, -2.8691e-02,  9.0625e-02,\n",
            "          1.5053e-02, -4.7549e-02,  4.1389e-02,  1.7620e-02,  5.1999e-02,\n",
            "          7.1141e-02, -2.3346e-03,  3.3839e-02,  1.2698e-02,  8.1069e-02],\n",
            "        [-2.3092e-02,  6.7773e-02, -7.5263e-02, -8.3645e-02,  8.2789e-02,\n",
            "          8.4682e-02, -1.4548e-02,  6.9421e-02,  8.2029e-03, -3.4977e-02,\n",
            "         -6.5922e-03,  4.4321e-02, -3.5689e-02,  5.4909e-02,  9.0141e-02,\n",
            "         -5.7842e-02,  1.1879e-02,  8.5019e-02,  6.2676e-02,  2.7258e-02,\n",
            "         -9.0910e-02, -8.9887e-02, -1.3257e-02, -3.2987e-02, -8.1639e-02,\n",
            "         -4.6179e-02,  5.4333e-02,  8.0646e-02,  4.4877e-02, -3.2881e-02,\n",
            "         -5.4185e-02, -6.9321e-02,  7.8552e-02, -2.6273e-02, -6.2827e-02,\n",
            "         -9.1750e-02, -8.5089e-02,  1.6593e-02,  7.1706e-02,  8.1882e-02,\n",
            "         -9.2506e-02,  6.4729e-02,  6.0508e-02,  7.3993e-02,  4.3495e-02,\n",
            "         -3.2979e-02,  2.3695e-02, -9.0679e-02, -8.9749e-02, -8.9626e-02,\n",
            "         -1.5971e-02,  4.2746e-02, -7.0698e-02,  7.4475e-02, -6.1471e-02,\n",
            "         -1.1888e-02, -3.5842e-04,  8.8910e-02, -4.0302e-03,  8.7842e-02,\n",
            "         -7.2292e-02,  1.5603e-02,  4.5772e-03,  5.2797e-02, -6.3094e-03,\n",
            "          2.6698e-02,  6.3985e-02,  8.5051e-02, -4.0277e-04,  4.1150e-02,\n",
            "         -7.6791e-02,  2.9179e-03,  2.2992e-02,  6.4099e-02,  1.1577e-02,\n",
            "          4.0272e-02, -9.7069e-03, -9.9359e-03, -8.4332e-02,  4.1267e-02,\n",
            "         -8.8173e-02, -7.5403e-02,  3.6836e-02, -8.2133e-02, -8.7759e-02,\n",
            "          2.6610e-03, -1.5777e-02,  2.8531e-02, -7.0188e-02,  4.7277e-02,\n",
            "         -7.3577e-03,  1.6131e-02,  4.8903e-02,  8.9636e-02,  3.2631e-02,\n",
            "         -9.6123e-03, -7.6644e-02, -1.6570e-02,  6.0471e-02,  5.9882e-02],\n",
            "        [ 6.6758e-03,  8.7122e-02, -3.1369e-02,  7.4299e-02,  2.7565e-02,\n",
            "         -6.6445e-02, -5.8710e-02,  8.0759e-02, -3.4108e-02,  8.9467e-02,\n",
            "          3.3615e-02,  8.1638e-02, -3.1254e-02,  4.8873e-02, -6.5727e-02,\n",
            "         -7.9016e-02,  3.2209e-02,  3.4353e-02, -6.4692e-03, -4.4445e-02,\n",
            "         -9.8541e-03,  1.9397e-02, -3.6645e-03, -6.8139e-02,  7.6673e-02,\n",
            "         -9.2849e-03, -5.2193e-02,  4.6387e-02,  8.9959e-02,  8.2026e-02,\n",
            "         -5.4617e-02, -2.8578e-02,  1.9002e-03,  4.9559e-02, -4.0968e-02,\n",
            "          5.3946e-02, -6.7246e-03,  3.4551e-03,  2.9208e-02, -8.4235e-02,\n",
            "          3.6336e-02,  9.2270e-02, -5.8170e-02, -6.9421e-02,  4.6352e-02,\n",
            "         -6.1595e-02,  5.3891e-02, -3.2864e-02,  8.9843e-02,  7.3294e-02,\n",
            "          3.1206e-02, -4.8829e-02, -1.7864e-03,  8.0840e-03, -8.3842e-02,\n",
            "          1.2909e-02,  6.5597e-03,  5.2506e-02, -2.0647e-02,  7.1879e-02,\n",
            "          1.0647e-02, -7.3873e-02,  1.1915e-02, -4.9864e-04, -1.5329e-02,\n",
            "         -2.8839e-02, -3.7201e-02,  1.5162e-02, -5.0112e-02, -7.1547e-02,\n",
            "         -1.2153e-02, -6.2771e-02, -5.5789e-02, -5.9124e-02,  1.5915e-02,\n",
            "         -2.2723e-02,  3.1779e-03,  5.0690e-02, -3.2320e-02,  3.7893e-02,\n",
            "          6.0165e-02,  3.0560e-02,  4.6934e-02, -5.0177e-02,  5.0640e-02,\n",
            "          1.5014e-02, -2.1112e-02,  9.4096e-02,  9.1810e-02,  3.9692e-02,\n",
            "         -8.2290e-04,  1.3069e-02, -6.2220e-02, -2.1776e-03, -5.7882e-02,\n",
            "          8.8098e-03, -3.4365e-02,  2.1895e-02, -4.2280e-02, -1.9752e-02]],\n",
            "       device='cuda:0', requires_grad=True), Parameter containing:\n",
            "tensor([ 0.0518, -0.0093, -0.0902,  0.0745, -0.0296,  0.0594, -0.0637, -0.0044,\n",
            "        -0.0928, -0.0846], device='cuda:0', requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFTd2eqOE41j"
      },
      "source": [
        "## 5. Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAvYqaFDE41j",
        "outputId": "321f166f-5825-4181-b584-da9ad9536ec0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for image,label in test_loader:\n",
        "      x = image.to(device)\n",
        "      y_= label.to(device)\n",
        "\n",
        "      output = model.forward(x)\n",
        "      _,output_index = torch.max(output,1)\n",
        "\n",
        "      total += label.size(0)\n",
        "      correct += (output_index == y_).sum().float()\n",
        "\n",
        "  print(\"Accuracy of Test Data: {}\".format(100*correct/total))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Test Data: 10.09615421295166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWEMvjFQN4w-"
      },
      "source": [
        "## 정확도가 왜 이렇게 낮을까?\n",
        "\n",
        "- 먼저 다른 기법들을 배워보면 이유를 알 수 있습니다!\n",
        "\n",
        "\n",
        "5/10 현호 생각\n",
        "1.   Optim = SGD? Adam 써야 좋은 결과\n",
        "2.   Num_Epoch = 10? 장난하나 ㅋ\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8T7RgTDxOIvL"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.1)\n",
        "num_epoch = 100"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_epoch):\n",
        "    for j,[image,label] in enumerate(train_loader):\n",
        "        x = image.to(device)\n",
        "        y_= label.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        output = model.forward(x)\n",
        "        loss = loss_func(output,y_)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "    if i % 10 == 0:\n",
        "        print(loss)          "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "aaXobLIBGW8O",
        "outputId": "9c2ded39-b247-40f5-89ac-aeec8562cc52"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.5654, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3326, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3362, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-ea90ea242386>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0my_\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1330\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1293\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for image,label in test_loader:\n",
        "      x = image.to(device)\n",
        "      y_= label.to(device)\n",
        "\n",
        "      output = model.forward(x)\n",
        "      _,output_index = torch.max(output,1)\n",
        "\n",
        "      total += label.size(0)\n",
        "      correct += (output_index == y_).sum().float()\n",
        "\n",
        "  print(\"Accuracy of Test Data: {}\".format(100*correct/total))\n",
        "\n",
        "#시간 너무 오래걸려서 멈춤...ㅋㅋㅋ 근데 에폭 50 돌렸는데 10->93?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0OYMbGWGctl",
        "outputId": "edd97810-e337-4711-995b-57a769884c8a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Test Data: 93.359375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YfIYpWI0HpJN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}